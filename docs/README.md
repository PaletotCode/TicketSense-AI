# TicketSense-AI ‚Äî Documenta√ß√£o Oficial

> Vers√£o 1.0 ¬∑ Atualizado em 01/11/2025  
> Contato t√©cnico: equipe@ticketsense.ai

---

## √çndice
1. [Vis√£o Geral](#vis√£o-geral)
2. [Arquitetura do Projeto](#arquitetura-do-projeto)
3. [Prepara√ß√£o do Ambiente](#prepara√ß√£o-do-ambiente)
4. [Fluxo Operacional](#fluxo-operacional)
5. [Detalhes por Componente](#detalhes-por-componente)
6. [Painel Administrativo (opcional)](#painel-administrativo-opcional)
7. [Qualidade e Avalia√ß√£o](#qualidade-e-avalia√ß√£o)
8. [Diretrizes de Contribui√ß√£o](#diretrizes-de-contribui√ß√£o)
9. [Gloss√°rio de Termos](#gloss√°rio-de-termos)

---

## Vis√£o Geral

TicketSense-AI √© uma plataforma de **classifica√ß√£o multi-inten√ß√£o** com foco em atendimento comercial. Ela identifica, em tempo real, o motivo de contato de um cliente e fornece at√© tr√™s inten√ß√µes ordenadas (com probabilidades) ‚Äî base para copilotos de vendas, an√°lise de leads e automa√ß√£o de respostas.

O MVP atual entrega:
- **Classifica√ß√£o de inten√ß√µes** com modelo `microsoft/mdeberta-v3-base` fine-tunado.
- **Gera√ß√£o sint√©tica** (Gemini 2.0) com receita focada em leads.
- **Painel opcional** para orquestrar gera√ß√£o, treino, hist√≥rico e comandos.
- **Ferramentas de qualidade** (auditoria, avalia√ß√£o) e pipelines padronizados via `Makefile`.

---

## Arquitetura do Projeto

```
pingfy_ia/
‚îú‚îÄ‚îÄ api/                     # FastAPI (infer√™ncia + endpoints administrativos)
‚îú‚îÄ‚îÄ config/                  # Configura√ß√µes centralizadas (.env ‚Üí dataclasses)
‚îú‚îÄ‚îÄ docs/                    # Documenta√ß√£o (este diret√≥rio)
‚îú‚îÄ‚îÄ scripts/                 # CLIs de gera√ß√£o, valida√ß√£o, auditoria, avalia√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ utils/               # Receita, clients LLM, prompt helpers
‚îú‚îÄ‚îÄ trainer/                 # Pipeline de treinamento (dataset, modelo, loop HF)
‚îú‚îÄ‚îÄ artifacts/               # Modelos, logs, checkpoints (gerados em runtime)
‚îú‚îÄ‚îÄ data/                    # Datasets locais (.jsonl) (gerados em runtime)
‚îú‚îÄ‚îÄ requirements.txt         # Depend√™ncias Python
‚îú‚îÄ‚îÄ Makefile                 # Comandos padronizados
‚îî‚îÄ‚îÄ MANUAL_USO.md            # Guia r√°pido (para m√£o na massa)
```

Componentes-chave:
- **API FastAPI** (`api/`): responde `/predict_intent` com top‚Äë3 intents e expose endpoints de administra√ß√£o.
- **Scripts** (`scripts/`) para gera√ß√£o (Gemini), valida√ß√£o, auditoria e avalia√ß√£o.
- **Trainer** (`trainer/`) com HuggingFace Trainer + utilidades (dataset, tokenizer, modelo).
- **Receita** (`scripts/utils/dataset_recipe.py`) com ~15k amostras direcionadas a LEAD_INTENT.
- **Painel** (opcional, em `admin_control_panel/`, fora deste documento).

---

## Prepara√ß√£o do Ambiente

### Requisitos m√≠nimos
- macOS (Apple Silicon M-series) ou Linux x86_64.
- Python 3.10+; Node.js apenas para o painel opcional.
- Conta Google com acesso ao Gemini 2.0 free tier.

### Passos iniciais
```bash
git clone <repo>
cd pingfy_ia
python3 -m venv venv
source venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

### Vari√°veis de ambiente (.env)
Coloque na raiz (`.env`):
```env
GEMINI_API_KEY=seu_token
OPENAI_API_KEY=opcional
GCS_BUCKET_NAME=pingfy-dataset
GCS_DATASET_PATH=data/synthetic_dataset.jsonl
```
Se precisar de GCS upload: `GOOGLE_APPLICATION_CREDENTIALS=/caminho/para/service-account.json`.

---

## Fluxo Operacional

O `Makefile` padroniza os passos. A tabela abaixo resume:

| Comando | A√ß√£o |
|---------|------|
| `make env` | Cria venv + instala deps |
| `make dataset` | Gera dataset do zero |
| `make resume` | Retoma gera√ß√£o (usa arquivo atual) |
| `make validate` | `prepare_dataset.py --analysis` |
| `make quality` | Auditoria (`analise_qualidade_dataset.py`) |
| `make train` | Treino completo (`LOCAL_DATASET_PATH=...`) |
| `make eval` | Avalia√ß√£o (`evaluate_model.py --threshold 0.4`) |
| `make api` | Sobe FastAPI com reload |
| `make clean` | Remove venv/checkpoints (cautela) |

Fluxo t√≠pico (end-to-end):
1. `make env` ‚Äî primeiro uso.
2. `make resume` ‚Äî gera dataset `data/synthetic_dataset_v2.jsonl`.
3. `make validate` e/ou `make quality` ‚Äî garante distribui√ß√£o e qualidade.
4. `make train` ‚Äî fine-tuning do modelo mDeBERTa (salva em `artifacts/best_model/`).
5. `make eval` ‚Äî checa m√©tricas (F1, hit@3).
6. `make api` ‚Äî serve modelo em `http://localhost:8000`.

---

## Detalhes por Componente

### 1. Configura√ß√£o (`config/`)
- **config.py**: carrega `.env`, define `ModelConfig`, `TrainingConfig`, `APIConfig`, `GCSConfig`.  
  - `model_name = "microsoft/mdeberta-v3-base"`  
  - Intents padr√£o incluem `LEAD_INTENT` como primeira classe.
- `DEVICE` seleciona automaticamente MPS / CUDA / CPU.

### 2. Dataset sint√©tico (`scripts/utils/`)
- **dataset_recipe.py**: lista de `GenerationTask` (singles e combina√ß√µes) totalizando 15k amostras.  
  - LEAD_INTENT e combos com UPGRADE/INFORMATION/PAYMENT t√™m prioridade.  
  - T√©cnicos (TECHNICAL_ISSUE) refor√ßados com COMPLAINT/SUPPORT.  
- **generate_synthetic_dataset.py**:  
  - CLI com `--resume`, `--analysis`, logging e valida√ß√£o.  
  - `get_client` usa `GeminiClient` (`gemini-2.0-flash-lite`) por padr√£o.  
  - Salva incrementalmente e retoma facilmente.
- **generation_utils.py**: prompt padr√£o, parser incremental (`iter_json_objects`), valida√ß√£o de sample.
- **llm_clients.py**:  
  - `GeminiClient`, `OpenAIClient`, `MockClient`.  
  - Controle de temperatura, fallback se a primeira chamada falhar.

### 3. Scripts operacionais (`scripts/`)
- **prepare_dataset.py**: valida/analisa dataset local (`--dataset`, `--analysis`).  
- **analise_qualidade_dataset.py**: relat√≥rio de variabilidade, duplicatas, baixa qualidade, exporta JSON/CSV.  
- **evaluate_model.py**: rodar p√≥s-treino (`--threshold`, `--topk`); inclui LEAD combos.

### 4. Treinador (`trainer/`)
- **dataset_utils.py**:  
  - `ensure_dataset()` (; evita download GCS sem credenciais).  
  - `load_dataset()` parse JSONL (com buffer para linhas quebradas).  
  - `select_indices()` com fallback quando estratifica√ß√£o falha.  
  - `IntentDataset` wrapper (torch tensor).
- **model_utils.py**:  
  - `create_tokenizer(use_fast=False)` para mDeBERTa (evita convers√£o tiktoken).  
  - `create_model()` carrega `AutoModelForSequenceClassification` com `problem_type="multi_label_classification"`.
- **train.py**:  
  - Logging em `artifacts/logs/training.log`.  
  - `TrainingArguments`: batch size 1 + grad accumulation (controlado por config).  
  - Sem `gradient_checkpointing` (maior estabilidade em MPS).  
  - Salva melhor modelo em `artifacts/best_model/`, label map e tokenizer.

### 5. API (`api/`)
- **inference.py**:  
  - Carrega best_model + tokenizer no startup.  
  - `/predict_intent`: retorna `intent`, `confidence`, lista `intents` (top‚Äë3 com threshold 0.35), `all_probabilities` opcional.  
  - `/predict_batch`, `/health`, `/model_info`.  
- **schemas.py**: modelos Pydantic (requests/responses).  
- **admin.py**:  
  - `/admin/dashboard`, `/admin/training/history`, `/admin/models`, `/admin/models/activate`.  
  - `/admin/training/start` + `/admin/training/stream` (SSE).  
  - `/admin/commands/run`: executa comandos locais (auto usa `sys.executable` para python).  
  - `TrainingManager` gerencia fila, broadcast de logs, parse de m√©tricas.

### 6. Painel (opcional)
Reposit√≥rio possui `admin_control_panel/` (React + Vite + Tailwind). Funcionalidades:
  - Dashboard com gr√°ficos de evolu√ß√£o (`MetricTrends`), datasets e playground de infer√™ncia.  
  - Abas: Treinamento (logs em tempo real), Modelos (ativar best_model), Hist√≥rico (tabela), Automa√ß√£o (biblioteca de comandos), Configura√ß√µes (vari√°veis r√°pidas).  
  - Depende dos endpoints `/admin`. N√£o √© obrigat√≥rio para usar a API core.

---

## Qualidade e Avalia√ß√£o

### Auditoria (qualidade sint√©tica)
```bash
make quality
# outputs:
# - artifacts/logs/dataset_quality.json
# - artifacts/logs/dataset_quality.csv
```

### Avalia√ß√£o do modelo
```bash
make eval  # threshold 0.4, topk 3
```
M√©tricas esperadas (√∫ltimo treino):
- Subset accuracy ‚âà 0.56‚Äì0.58 (teste fixo)
- Hit@3 ‚âà 0.95
- F1 micro ‚âà 0.68 (threshold 0.5) / 0.7+ com threshold calibrado
- LEAD_INTENT recall 1.0; technical/commercial combos acima de 0.7 F1.

---

## Diretrizes de Contribui√ß√£o

1. Use `make env` + `make resume` antes de mexer.  
2. Atualize receita (`dataset_recipe.py`) com cuidado ‚Äî mantenha `TOTAL_SAMPLES`.  
3. Sempre rode `make validate` + `make train` + `make eval` antes de subir pull request.  
4. Documente m√©tricas novas no `MANUAL_USO.md` e, se for relevante, adapta√ß√µes no painel.
5. Para novos scripts, anexe instru√ß√µes no manual e considere ganhar um atalho no Makefile.

---

## Gloss√°rio de Termos

| Termo | Significado |
|-------|-------------|
| **Inten√ß√£o (Intent)** | Motivo de contato identificado pela IA (ex.: `LEAD_INTENT`, `PAYMENT`). |
| **Multi-inten√ß√£o** | Quando uma mensagem tem mais de uma inten√ß√£o relevante (ex.: `["PAYMENT", "SUPPORT"]`). |
| **LEAD_INTENT** | Inten√ß√£o que identifica um potencial comprador ou oportunidade de venda. |
| **Dataset sint√©tico** | Conjunto de dados gerado artificialmente (neste caso, via Gemini) seguindo nossa receita. |
| **Gemini 2.0 flash-lite** | Modelo LLM gratuito do Google usado para gerar exemplos sint√©ticos. |
| **Recipe** | Arquivo que define quantas amostras gerar por inten√ß√£o/combo (`dataset_recipe.py`). |
| **Resume** | Recuperar gera√ß√£o interrompida; o script l√™ o arquivo existente e calcula o saldo. |
| **MDEBERTa-V3-Base** | Modelo transformer da Microsoft, usado como backbone para classifica√ß√£o. |
| **Gradient accumulation** | T√©cnica para simular batch maior acumulando gradientes antes do update. |
| **Subset accuracy** | M√©trica que s√≥ conta acerto quando todas as inten√ß√µes da mensagem foram previstas corretamente. |
| **Hit@K** | Percentual de casos em que a inten√ß√£o correta aparece entre as K sugest√µes principais. |
| **F1 micro** | M√©dia harm√¥nica de precis√£o e recall considerando todos os r√≥tulos (multi-label). |
| **SSE (Server-Sent Events)** | Protocolo para enviar logs/status cont√≠nuos do backend para o painel. |
| **Pipeline** | Sequ√™ncia de etapas (gera√ß√£o ‚Üí valida√ß√£o ‚Üí treino ‚Üí avalia√ß√£o ‚Üí infer√™ncia). |
| **Makefile** | Arquivo que define comandos r√°pidos (`make <alvo>`) para automatizar tarefas. |
| **Painel admin** | Interface web opcional que consome os endpoints `/admin/` para monitorar/acionar tarefas. |

---

**D√∫vidas?** Abra uma issue ou contate a equipe t√©cnica. Esta documenta√ß√£o deve ser mantida em sincronia com o c√≥digo-fonte ‚Äî sinta-se √† vontade para propor melhorias. üöÄ
